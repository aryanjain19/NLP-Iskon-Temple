{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"newsgroups_topic_modeling.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"n20P4Zceh1nC","colab_type":"text"},"source":["# Topic Modeling"]},{"cell_type":"markdown","metadata":{"id":"u1QeiS2Ph1nF","colab_type":"text"},"source":["In machine learning and natural language processing, a topic model is a type of **statistical model for discovering the abstract \"topics\" that occur in a collection of documents.**\n","\n","Topic modeling is a frequently used text-mining tool for discovery of **hidden semantic structures** in a text body. "]},{"cell_type":"markdown","metadata":{"id":"Uo4Drk70h1nG","colab_type":"text"},"source":["**How do we capture the hidden semantic structures?**\n","\n","**Intuitively**, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \n","- \"dog\" and \"bone\" will appear more often in documents about dogs, \n","- \"cat\" and \"meow\" will appear in documents about cats, and \n","- \"the\" and \"is\" will appear equally in both. \n","\n","A document typically concerns multiple topics in different proportions; thus, in a document that is 10% about cats and 90% about dogs, there would probably be about 9 times more dog words than cat words. \n","\n","**The \"topics\" produced by topic modeling techniques are clusters of similar words.**\n","\n","**A topic model** captures this intuition in a mathematical framework, which allows examining a set of documents and discovering, based on the statistics of the words in each, what the topics might be and what each document's balance of topics is.\n","\n","Source: [Topic Modeling](https://en.wikipedia.org/wiki/Topic_model)"]},{"cell_type":"markdown","metadata":{"id":"LyXDSp-bh1nG","colab_type":"text"},"source":["## Applications in industry"]},{"cell_type":"markdown","metadata":{"id":"w1uZ1iqqh1nH","colab_type":"text"},"source":["- Publications/Newspapers have several articles (documents) across various topics. These documents could be from either sports, medicine, technology, health, business, media, entertainment. They would want to categorize each document into a specific topic. We could also place multiple topics to same document, for instance, an article speaking about Pele could have topics such as sports, football, and celebrity.\n","\n","- Banks or any enterprise would have multiple documents and they would want to automatically categorize the documents as information, customer grievance, enquiry, sales, product description etc.\n","\n","- Web based companies such as Stack Overflow, Quora would want to automate the tagging/categorization of the question. \n","\n","- This is used as pre-step to supervised techniques. For instance, for chat applications, an interaction is categorized by topic modeling and is assigned to the customer agent, however, if this is wrongly assigned, the category is updated and over time we get more information of the interaction-category (right). Once sufficient data is available, it becomes a multi-label multi-classification problem."]},{"cell_type":"markdown","metadata":{"id":"qciCzG24h1nI","colab_type":"text"},"source":["## Dataset (Unsupervised Technique)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k70loXCzh1nJ","colab_type":"text"},"source":["We shall use the 20 newsgroups dataset. \n","\n","[Dataset Description](http://qwone.com/~jason/20Newsgroups/)\n","\n","It comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date.\n","\n","However, since we are doing topic modeling, we shall not use the topic labels but will use for verification/evaluation."]},{"cell_type":"code","metadata":{"id":"LbgrKRffh1nJ","colab_type":"code","outputId":"1854663f-9093-4b8c-cc82-21087ccc4b51","colab":{}},"source":["from sklearn.datasets import fetch_20newsgroups\n","newsgroups_train = fetch_20newsgroups(subset='train')\n","\n","from pprint import pprint\n","pprint(list(newsgroups_train.target_names))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['alt.atheism',\n"," 'comp.graphics',\n"," 'comp.os.ms-windows.misc',\n"," 'comp.sys.ibm.pc.hardware',\n"," 'comp.sys.mac.hardware',\n"," 'comp.windows.x',\n"," 'misc.forsale',\n"," 'rec.autos',\n"," 'rec.motorcycles',\n"," 'rec.sport.baseball',\n"," 'rec.sport.hockey',\n"," 'sci.crypt',\n"," 'sci.electronics',\n"," 'sci.med',\n"," 'sci.space',\n"," 'soc.religion.christian',\n"," 'talk.politics.guns',\n"," 'talk.politics.mideast',\n"," 'talk.politics.misc',\n"," 'talk.religion.misc']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VGQgfNvzh1nN","colab_type":"text"},"source":["**For this exercise, we shall take only 4 newsgroups.**"]},{"cell_type":"code","metadata":{"id":"MgiEtSGth1nN","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","from sklearn import decomposition\n","from scipy import linalg\n","\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQLmn9Bfh1nP","colab_type":"code","colab":{}},"source":["categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n","remove = ('headers', 'footers', 'quotes')\n","\n","newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n","newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=remove)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YV3we3ubh1nR","colab_type":"text"},"source":["### Data Exploration"]},{"cell_type":"code","metadata":{"id":"TS_DtZd6h1nR","colab_type":"code","outputId":"b26659ac-5317-454f-ef5b-4dcbfe8fecbc","colab":{}},"source":["newsgroups_train.filenames.shape, newsgroups_train.target.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2034,), (2034,))"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"OJyW-Essh1nT","colab_type":"code","outputId":"a69143e6-c40b-490b-fc7f-1480e4489d24","colab":{}},"source":["print(\"\\n--------------------------------\".join(newsgroups_train.data[:3]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Hi,\n","\n","I've noticed that if you only save a model (with all your mapping planes\n","positioned carefully) to a .3DS file that when you reload it after restarting\n","3DS, they are given a default position and orientation.  But if you save\n","to a .PRJ file their positions/orientation are preserved.  Does anyone\n","know why this information is not stored in the .3DS file?  Nothing is\n","explicitly said in the manual about saving texture rules in the .PRJ file. \n","I'd like to be able to read the texture rule information, does anyone have \n","the format for the .PRJ file?\n","\n","Is the .CEL file format available from somewhere?\n","\n","Rych\n","--------------------------------\n","\n","Seems to be, barring evidence to the contrary, that Koresh was simply\n","another deranged fanatic who thought it neccessary to take a whole bunch of\n","folks with him, children and all, to satisfy his delusional mania. Jim\n","Jones, circa 1993.\n","\n","\n","Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n","for centuries.\n","--------------------------------\n"," >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n","\n","MB>                                                             So the\n","MB> 1970 figure seems unlikely to actually be anything but a perijove.\n","\n","JG>Sorry, _perijoves_...I'm not used to talking this language.\n","\n","Couldn't we just say periapsis or apoapsis?\n","\n"," \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UkAqQz6ah1nV","colab_type":"code","outputId":"d6c2f2fb-5110-47f1-c1d2-4ff333512a0c","colab":{}},"source":["np.array(newsgroups_train.target_names)[newsgroups_train.target[:3]]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['comp.graphics', 'talk.religion.misc', 'sci.space'], dtype='<U18')"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"ZPBH0f0Mh1nX","colab_type":"text"},"source":["## Topic Modeling Implementation"]},{"cell_type":"markdown","metadata":{"id":"QbGUaFF_h1nY","colab_type":"text"},"source":["### Intuition of using Matrix Decomposition/Matrix Factorization"]},{"cell_type":"markdown","metadata":{"id":"6CsiO0feh1nY","colab_type":"text"},"source":["Factorization is to get the factors. E.g. 36 -> 2 * 2 * 3 * 3. So, the prime factors are 2 and 3. \n","\n","Similarly, we try to find the factors of the matrix. For instance, in the below image, background and the people are two factors, which could be separated as shown.\n","\n","![Matrix_Decomposition](https://i.imgur.com/n1xxjlx.png)\n"]},{"cell_type":"markdown","metadata":{"id":"i_Be9rNFh1nZ","colab_type":"text"},"source":["### Singular Value Decomposition"]},{"cell_type":"markdown","metadata":{"id":"t3wSZWXch1nZ","colab_type":"text"},"source":["Before we get into the theory let us understand the output, so that we can relate back to the concept.\n","\n","[topic_modeling_output](../excel/topic_modeling_literature.xlsx)\n"]},{"cell_type":"markdown","metadata":{"id":"fOn3flpVh1na","colab_type":"text"},"source":["The singular value decomposition of an __m * n__ matrix **M** is a factorization of the form $U \\Sigma V^T$ , \n","\n","where,\n","- __U__ is an _m * m_ matrix, \n","\n","- $\\Sigma$ is an _m * n_ rectangular diagonal matrix with non-negative real numbers on the diagonal and \n","\n","- **V** is _n * n_ matrix.\n","\n","    \n","The diagonal entries of $\\Sigma$ are known as the **singular values of M**. \n","\n","The **columns of U and the columns of V** are called the **left-singular vectors and right-singular vectors of M**.\n","\n","**Singular Vectors** -> Those vectors/matrices whose determinant is 0 i.e. it does not have an inverse matrix and hence singular (remember it as single)."]},{"cell_type":"markdown","metadata":{"id":"SGN9KzwYh1na","colab_type":"text"},"source":["![SVD](https://i.imgur.com/M1fqdVe.png)\n","\n","Source: [SVD_Wikipedia](https://en.wikipedia.org/wiki/Singular_value_decomposition)\n","\n","\n","\n","\n","\n","As per the above image,\n","\n","$V^*$ is same as $V^T$.\n","\n","$U$ . $U^T$ i.e. dot product of U with itself is one.\n","\n","$V$ . $V^T$ i.e. dot product of U with itself is one."]},{"cell_type":"markdown","metadata":{"id":"carw30JPh1nb","colab_type":"text"},"source":["**Better visualization of the matrix factors:**\n","\n","![SVD_Partial_matrix](https://i.imgur.com/jZCx0Kx.png)\n","(source: [Facebook Research: Fast Randomized SVD](https://research.fb.com/fast-randomized-svd/))"]},{"cell_type":"markdown","metadata":{"id":"n7MTZkZUh1nb","colab_type":"text"},"source":["**Properties of U, s and V matrices?**\n","\n","The SVD algorithm factorizes a matrix into one matrix (U matrix) with **orthonormal columns** and one with **orthonormal rows** ($V^T$ matrix), along with a __diagonal matrix (s matrix)__, which contains the **relative importance** of each factor.\n","\n","The columns of U matrix and rows of the $V^T$ matrix are **orthonormal** to each other.\n","\n","**What is orthonormal?**\n","\n","In linear algebra, two vectors are orthonormal if they are orthogonal and unit vectors.\n","- Orthogonal -> The vectors are perpendicular to each other i.e. the dot product is 0.\n","- Unit Vectors -> The length/magnitude of the vectors is unity i.e. dot product of the vector with itself is 1.\n","\n","[Orthonormal - wiki](https://en.wikipedia.org/wiki/Orthonormality#Simple_example)\n","\n","**But what does orthogonal mean in the context of topics?**\n","\n","We would clearly expect that the words that appear most frequently in one topic would appear less frequently in the other - otherwise that word wouldn't make a good choice to separate out the two topics. Therefore, we expect the topics to be **orthogonal** i.e. less over-lapping.\n","\n","**What does s matrix represent?**\n","\n","**s matrix** has non-negative values in descending order and it represents the importance of the topics."]},{"cell_type":"markdown","metadata":{"id":"9GdpskLch1nc","colab_type":"text"},"source":["#### Implementation - SVD"]},{"cell_type":"markdown","metadata":{"id":"SGk3IO_9h1nc","colab_type":"text"},"source":["Notice that this representation does not take into account word order or sentence structure.  It's an example of a **bag of words** approach. So let us get the CountVectorizer or TfidfVectorizer to get the term-document matrices."]},{"cell_type":"code","metadata":{"id":"tQh_eWtXh1nd","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXNwWaLrh1nf","colab_type":"code","colab":{}},"source":["vectorizer = CountVectorizer(stop_words='english')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rT6ZQN9eh1nh","colab_type":"code","outputId":"77780121-b92b-4fcd-8fdc-246a4075cff4","colab":{}},"source":["vectors = vectorizer.fit_transform(newsgroups_train.data).todense() # (documents, vocab)\n","vectors.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 26576)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"q7RM1NM8h1nl","colab_type":"code","outputId":"6e98a38c-e434-43e3-d6f1-47be8b290baf","colab":{}},"source":["vocab = np.array(vectorizer.get_feature_names())\n","print(vocab.size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["26576\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"txkkthrGh1nn","colab_type":"code","outputId":"acf91594-026b-44d2-f101-9a5f0e3f2d6c","colab":{}},"source":["vocab[5000:5020]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['brow', 'brown', 'browning', 'browns', 'browse', 'browsing',\n","       'bruce', 'bruces', 'bruise', 'bruised', 'bruises', 'brunner',\n","       'brush', 'brushmapping', 'brushmaps', 'brussel', 'brutal',\n","       'brutally', 'brute', 'bryan'], dtype='<U80')"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"LWUV44FUh1np","colab_type":"code","outputId":"30792a61-d122-47fb-e744-85f7fd4a558c","colab":{}},"source":["%time U, s, Vt = linalg.svd(vectors, full_matrices=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wall time: 11.3 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ii4VHiTSh1nq","colab_type":"text"},"source":["**NOTE**\n","\n","**full_matrices = True -> would get matrix U.shape as m * m i.e. 2034 * 2034 and Vt.shape as 26576 * 26576.**\n","\n","**When full_matrices = False, we use k=min(m,n). The dimensions would be m * k (2034 * 2034) and k * n (2034 * 26576).**\n","\n","See **Appendix** (below) for further explanation."]},{"cell_type":"code","metadata":{"id":"nn3lhlShh1nr","colab_type":"code","outputId":"1fb360f6-f970-4337-bdd0-4c2c4cbbd9fa","colab":{}},"source":["print(U.shape, s.shape, Vt.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2034, 2034) (2034,) (2034, 26576)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0AsM_xk6h1nt","colab_type":"code","colab":{}},"source":["num_top_words=8\n","\n","def show_topics(a):\n","    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]]\n","    topic_words = ([top_words(t) for t in a])\n","    return [' '.join(t) for t in topic_words]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjtIpvPFh1nv","colab_type":"code","outputId":"22b75d4b-97cf-4bab-f4be-b7a89467d249","colab":{}},"source":["show_topics(Vt[:10])  # We would have 2034 topics and if we want to reduce it to just few topics, we would need to use truncated SVD or NMF."],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ditto critus propagandist surname galacticentric kindergarten surreal imaginative',\n"," 'jpeg gif file color quality image jfif format',\n"," 'graphics edu pub mail 128 3d ray ftp',\n"," 'jesus god matthew people atheists atheism does graphics',\n"," 'image data processing analysis software available tools display',\n"," 'god atheists atheism religious believe religion argument true',\n"," 'space nasa lunar mars probe moon missions probes',\n"," 'image probe surface lunar mars probes moon orbit',\n"," 'argument fallacy conclusion example true ad argumentum premises',\n"," 'space larson image theory universe physical nasa material']"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"Zvb96N8fh1nx","colab_type":"text"},"source":["We get topics that match the kinds of clusters we would expect! This is despite the fact that this is an unsupervised algorithm - which is to say, we never actually told the algorithm how our documents are grouped."]},{"cell_type":"markdown","metadata":{"id":"Yvau2_5Dh1ny","colab_type":"text"},"source":["### Non-negative Matrix Factorization"]},{"cell_type":"markdown","metadata":{"id":"2OB7jXS0h1ny","colab_type":"text"},"source":["Just like we did for SVD, let us see how the output of NMF looks like.\n","\n","[NMF](../excel/topic_modeling_literature.xlsx)\n","\n","We see that instead of 3 matrices we just have 2 matrices and also we see that there is **NO** negative values. That was the idea behind NMF. \n","\n","In the SVD sheet of the excel, we see lots of negative values, which were not interpretable. With NMF, we just have positive values that enables interpretation, one of the reasons for its popularity."]},{"cell_type":"markdown","metadata":{"id":"ftVDAA5Rh1nz","colab_type":"text"},"source":["Rather than constraining our factors to be *orthogonal*, another idea would to constrain them to be *non-negative*. NMF is a factorization of a non-negative data set $V$: $$ V = W H$$ into non-negative matrices $W,\\; H$.\n"]},{"cell_type":"markdown","metadata":{"id":"sBfCK00qh1nz","colab_type":"text"},"source":["![NMF](https://i.imgur.com/nwiECNi.png)\n","\n","\n","The product of W and H **approximates** the non-negative matrix V and hence it is a non-exact factorization that factors into one skinny positive matrix and one short positive matrix.  "]},{"cell_type":"code","metadata":{"id":"zZWZ6xZBh1n0","colab_type":"code","colab":{}},"source":["m,n = vectors.shape\n","d = 5  # num topics"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DT55PTxth1n1","colab_type":"code","colab":{}},"source":["clf = decomposition.NMF(n_components=d, random_state=1)\n","\n","W1 = clf.fit_transform(vectors)\n","H1 = clf.components_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I_hPfkcjh1n3","colab_type":"code","outputId":"0ed8976f-3361-469d-d870-1f4d927b2201","colab":{}},"source":["show_topics(H1)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['jpeg image gif file color images format quality',\n"," 'edu graphics pub mail 128 ray ftp send',\n"," 'space launch satellite nasa commercial satellites year market',\n"," 'jesus god people matthew atheists does atheism said',\n"," 'image data available software processing ftp edu analysis']"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"QrSQWjFLh1n4","colab_type":"code","colab":{}},"source":["vectorizer_tfidf = TfidfVectorizer(stop_words='english')\n","vectors_tfidf = vectorizer_tfidf.fit_transform(newsgroups_train.data) # (documents, vocab)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqJtYEJLh1n6","colab_type":"code","colab":{}},"source":["W1 = clf.fit_transform(vectors_tfidf)\n","H1 = clf.components_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9XT_aGmh1n7","colab_type":"code","outputId":"e005cfa9-b632-4815-8a7a-684f774fde10","colab":{}},"source":["show_topics(H1)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['people don think just like objective say morality',\n"," 'graphics thanks files image file program windows know',\n"," 'space nasa launch shuttle orbit moon lunar earth',\n"," 'ico bobbe tek beauchaine bronx manhattan sank queens',\n"," 'god jesus bible believe christian atheism does belief']"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"KnNWBN2xh1n9","colab_type":"text"},"source":["**Notes:**\n","- For NMF, matrix needs to be at least as tall as it is wide, or we get an error with fit_transform\n","- Can use df_min in CountVectorizer to only look at words that were in at least k of the split texts"]},{"cell_type":"markdown","metadata":{"id":"YPzmFNSKh1n-","colab_type":"text"},"source":["### Truncated SVD (Latent Semantic Analysis)"]},{"cell_type":"markdown","metadata":{"id":"0HNfAHm2h1n-","colab_type":"text"},"source":["**Problem with SVD**\n","\n","SVD gave back 2034 topics -- so how do we get few topics, like the one we saw in the excel sheet? We need to use Truncated SVD."]},{"cell_type":"markdown","metadata":{"id":"OkGVktu2h1n_","colab_type":"text"},"source":["**Remedy:**\n","\n","Truncated SVD implements a variant of singular value decomposition (SVD) that only computes the **largest singular values, where is a user-specified parameter.**\n","\n","When truncated SVD is applied to term-document matrices (as returned by CountVectorizer or TfidfVectorizer), this transformation is known as latent semantic analysis (LSA), because it transforms such matrices to a **semantic space of low dimensionality.**"]},{"cell_type":"markdown","metadata":{"id":"I4PbPa-4h1oA","colab_type":"text"},"source":["**Relationship of Truncated SVD and PCA:**\n","\n","TruncatedSVD is very similar to PCA, but differs in that it works on sample matrices  directly instead of their covariance matrices. When the columnwise (per-feature) means of  are subtracted from the feature values, truncated SVD on the resulting matrix is equivalent to PCA.\n","\n","In Scikit-learn package, Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with scipy.sparse matrices efficiently."]},{"cell_type":"code","metadata":{"id":"RXlIATuKh1oA","colab_type":"code","colab":{}},"source":["from sklearn.utils.extmath import randomized_svd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rXEg-y3nh1oC","colab_type":"code","outputId":"ea122e1b-f65d-41b9-a754-9c6b4154774d","colab":{}},"source":["%time u, s, v = randomized_svd(vectors, 4)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wall time: 4.15 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IPutmeGlh1oD","colab_type":"code","outputId":"5fd6a75d-1675-48ee-a528-2e2f6b52d7b8","colab":{}},"source":["show_topics(v[:4])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['jpeg image edu file graphics images gif data',\n"," 'jpeg gif file color quality image jfif format',\n"," 'space jesus launch god people satellite matthew atheists',\n"," 'jesus god matthew people atheists atheism does graphics']"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"LOLYyrNOh1oF","colab_type":"text"},"source":["## Appendix"]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"pGnU2d6Oh1oG","colab_type":"text"},"source":["### Full and Reduced SVD (Reduced SVD is not same as Truncated)"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"fYhn5AV7h1oG","colab_type":"text"},"source":["Remember how we were calling `np.linalg.svd(vectors, full_matrices=False)`?  We set `full_matrices=False` to calculate the reduced SVD.  For the full SVD, both U and V are **square** matrices, where the extra columns in U form an orthonormal basis i.e. columns are orthonormal (but zero out when multiplied by extra rows of zeros in S).\n","\n","\n","We know that S matrix is rectangular in shape ( m * n ), but the output shows square matrix (m * m), that is because we do not consider them as those are rows of 0 and only the diagonal elements upto n (considering m >= n) are filled. Since these are zeros, multiplying part of U with zeros will yield to zeros and hence that part of the U matrix is cut-off. Hence, we see reduced SVD."]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"B7APM_xOh1oH","colab_type":"text"},"source":["![Full_Reduced_SVD](https://i.imgur.com/74GzBOZ.png)\n","\n","![Reduced SVD](https://i.imgur.com/Ya4rLMH.png)"]}]}