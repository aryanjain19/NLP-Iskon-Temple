{"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"BeautifulSoup.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"interpreter":{"hash":"c0f70214c0dd213f07f54ee5d6e0ea644bdbba35113c9bfe8aaa0d1db03ad5dd"}},"cells":[{"cell_type":"markdown","source":["# BeautifulSoup\n","\n","https://www.crummy.com/software/BeautifulSoup/bs4/doc/#\n","\n","BeautifulSoup is a Python library, which is used quickly extract (scrape) valid data from webpages, and this library gives facility to us to use what ever the parser you want like html.parser, lxml and html5lib.\n","\n"],"metadata":{"id":"BQgmJhFNmSH2"}},{"cell_type":"markdown","source":["**Installing & Importing prerequisites**"],"metadata":{"id":"EhyEaSqqmSIP"}},{"cell_type":"code","execution_count":2,"source":["import requests\r\n","from bs4 import BeautifulSoup"],"outputs":[],"metadata":{"id":"jopD6HU1mSIa"}},{"cell_type":"code","execution_count":3,"source":["simple_html = \"\"\"\r\n","\r\n","<html>\r\n","    <head>\r\n","        <title>Web Scraping Session</title>        \r\n","    </head>\r\n","\r\n","    <body>\r\n","        <p class=\"title\">\r\n","            <b>Simple HTML</b>\r\n","        </p>\r\n","\r\n","        <p class=\"begin start\">\r\n","        This is one of the sessions on web scraping and we have covered\r\n","\r\n","            <a href=\"http://abcd.com/request\" class=\"content\" id=\"link1\">requests</a>,\r\n","            <a href=\"http://abcd.com/parser\" class=\"content\" id=\"link2\">parser</a> and\r\n","            <a href=\"http://abcd.com/extractor\" class=\"content\" id=\"link3\">extractor</a>.\r\n","        </p>\r\n","\r\n","        <p class=\"end\">Let us move on to the next topic.</p>\r\n","    </body>\r\n","</html>\r\n","\r\n","\"\"\""],"outputs":[],"metadata":{"id":"ykrc2s96mSIb"}},{"cell_type":"markdown","source":["## Objects"],"metadata":{"id":"FvcwzuwflOJ1"}},{"cell_type":"markdown","source":["Beautiful Soup transforms a **complex HTML document into a complex tree of Python objects**. \n","\n","The most common kinds of objects we generally deal with are: \n","\n","1. BeautifulSoup\n","2. Tag\n","\n"],"metadata":{"id":"VI0d33a3lMEk"}},{"cell_type":"markdown","source":["### Soup Object\r\n","\r\n","The BeautifulSoup object represents the parsed document as a whole."],"metadata":{"id":"Hz1ss_7zJpqQ"}},{"cell_type":"code","execution_count":4,"source":["soup = BeautifulSoup(simple_html)"],"outputs":[],"metadata":{"id":"5spBGECpmSId"}},{"cell_type":"code","execution_count":5,"source":["print(soup.prettify())  # Indented soup object"],"outputs":[{"output_type":"stream","name":"stdout","text":["<html>\n"," <head>\n","  <title>\n","   Web Scraping Session\n","  </title>\n"," </head>\n"," <body>\n","  <p class=\"title\">\n","   <b>\n","    Simple HTML\n","   </b>\n","  </p>\n","  <p class=\"begin start\">\n","   This is one of the sessions on web scraping and we have covered\n","   <a class=\"content\" href=\"http://abcd.com/request\" id=\"link1\">\n","    requests\n","   </a>\n","   ,\n","   <a class=\"content\" href=\"http://abcd.com/parser\" id=\"link2\">\n","    parser\n","   </a>\n","   and\n","   <a class=\"content\" href=\"http://abcd.com/extractor\" id=\"link3\">\n","    extractor\n","   </a>\n","   .\n","  </p>\n","  <p class=\"end\">\n","   Let us move on to the next topic.\n","  </p>\n"," </body>\n","</html>\n","\n"]}],"metadata":{"id":"FLhy5plJmSIf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175023510,"user_tz":-330,"elapsed":563,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"31c2c6f9-549b-498b-d211-b27db671aa31"}},{"cell_type":"markdown","source":["### Tag object\n","\n","A Tag object corresponds to an XML or HTML tag in the original document:\n"],"metadata":{"id":"v0Mbmbk9nBRt"}},{"cell_type":"markdown","source":["#### Accessing elements/tags\n","\n","\n"],"metadata":{"id":"9hpASGnRJL-e"}},{"cell_type":"code","execution_count":6,"source":["tag = soup.title  # Takes the first attribute\r\n","print(tag)\r\n","print(type(tag))\r\n","print(tag.name)  # Every tag has a name, and we can access that name using \"name\" object."],"outputs":[{"output_type":"stream","name":"stdout","text":["<title>Web Scraping Session</title>\n","<class 'bs4.element.Tag'>\n","title\n"]}],"metadata":{"id":"-SPYDDEnmSIg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175028390,"user_tz":-330,"elapsed":1196,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"ac49bac0-84b0-47ec-909b-3d21d773995e"}},{"cell_type":"code","execution_count":7,"source":["soup.body"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<body>\n","<p class=\"title\">\n","<b>Simple HTML</b>\n","</p>\n","<p class=\"begin start\">\n","        This is one of the sessions on web scraping and we have covered\n","\n","            <a class=\"content\" href=\"http://abcd.com/request\" id=\"link1\">requests</a>,\n","            <a class=\"content\" href=\"http://abcd.com/parser\" id=\"link2\">parser</a> and\n","            <a class=\"content\" href=\"http://abcd.com/extractor\" id=\"link3\">extractor</a>.\n","        </p>\n","<p class=\"end\">Let us move on to the next topic.</p>\n","</body>"]},"metadata":{},"execution_count":7}],"metadata":{"id":"xIrIpHbKmSIj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175029564,"user_tz":-330,"elapsed":605,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"a767203a-681b-4b6d-f05f-95a0f5bba823"}},{"cell_type":"code","execution_count":8,"source":["soup.body.name"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["'body'"]},"metadata":{},"execution_count":8}],"metadata":{"id":"7jGEh7BzmSIl","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1621175031388,"user_tz":-330,"elapsed":599,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"2dd3ce63-39aa-465f-ce2b-ddc3fc30d997"}},{"cell_type":"code","execution_count":9,"source":["soup.body.parent.name"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["'html'"]},"metadata":{},"execution_count":9}],"metadata":{"id":"yBIlgHkTmSIm","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1621175032922,"user_tz":-330,"elapsed":884,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"696151e7-c503-4b6c-e03c-75814692a6ef"}},{"cell_type":"code","execution_count":11,"source":["soup.p"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<p class=\"title\">\n","<b>Simple HTML</b>\n","</p>"]},"metadata":{},"execution_count":11}],"metadata":{"id":"mzGhojlqmSIn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175034530,"user_tz":-330,"elapsed":844,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"4bcbe032-e982-4dc2-cf1d-5ce8f03ae822"}},{"cell_type":"code","execution_count":12,"source":["soup.a"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<a class=\"content\" href=\"http://abcd.com/request\" id=\"link1\">requests</a>"]},"metadata":{},"execution_count":12}],"metadata":{"id":"w40SjINdmSIp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175035687,"user_tz":-330,"elapsed":582,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"665ddd77-6cb5-4197-c816-cc8920198bdc"}},{"cell_type":"markdown","source":["#### Attributes of the tag\n","\n","A tag may have any number of attributes. We can access a tag’s attributes by treating the tag like a dictionary:"],"metadata":{"id":"jwXZMu3PZIN6"}},{"cell_type":"code","execution_count":13,"source":["tag = soup.a\r\n","tag"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<a class=\"content\" href=\"http://abcd.com/request\" id=\"link1\">requests</a>"]},"metadata":{},"execution_count":13}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"seFEs25uZLSR","executionInfo":{"status":"ok","timestamp":1621175038895,"user_tz":-330,"elapsed":1589,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"04b4b5bb-85a9-4555-8b39-dd42579dec00"}},{"cell_type":"code","execution_count":14,"source":["tag['href']"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["'http://abcd.com/request'"]},"metadata":{},"execution_count":14}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"xygNOzk_ZWYb","executionInfo":{"status":"ok","timestamp":1621175040440,"user_tz":-330,"elapsed":1064,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"5c9ee5e1-2e04-4d36-b45c-38a668f28736"}},{"cell_type":"code","execution_count":15,"source":["tag.attrs  # attrs is the dictionary"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'href': 'http://abcd.com/request', 'class': ['content'], 'id': 'link1'}"]},"metadata":{},"execution_count":15}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9t4smoHlZaRh","executionInfo":{"status":"ok","timestamp":1621175042854,"user_tz":-330,"elapsed":1640,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"9930e67a-6eb7-433b-b087-249e1768dcc3"}},{"cell_type":"markdown","source":["To access the attribute values in the form of a list we will use "],"metadata":{"id":"pFfdPoGoa9Xp"}},{"cell_type":"code","execution_count":16,"source":["tag.get_attribute_list('class')"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["['content']"]},"metadata":{},"execution_count":16}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cW6uOzkla6nq","executionInfo":{"status":"ok","timestamp":1621175045462,"user_tz":-330,"elapsed":824,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"0a21e2fc-5cbe-4900-c2fa-044e856fcf57"}},{"cell_type":"markdown","source":["## Different Types Of Parsers\n","BeautifulSoup supports different types of parsers, depends on what type of markup you want to parse. It supports “html”, “xml”, and “html5”\n","\n","https://www.crummy.com/software/BeautifulSoup/bs4/doc/#specifying-the-parser-to-use"],"metadata":{"id":"HoNaL0mxmSIr"}},{"cell_type":"markdown","source":["\n","The cool thing when you use Beautiful Soup is that you can have different parsers that work well even with ill-formatted HTML. We shall now create a soup object using this ill-formatted HTML. \n","\n","When we don't specify a parser, the default parser that is used is the lxml parser. This parser is very performant, it works extremely fast. It's lenient, it can work with ill-formatted HTML as well. \n","\n","\n","\n"],"metadata":{"id":"gRc6qwCPJHeh"}},{"cell_type":"code","execution_count":25,"source":["html = \"\"\"\r\n","    <h1><a /><b><th <td>\r\n","\"\"\""],"outputs":[],"metadata":{"id":"YD0DkhuomSIs"}},{"cell_type":"markdown","source":["Here is what the parsed HTML looks like with this parser. Observe that it is now well-formatted. "],"metadata":{"id":"gNk_iDTALnBu"}},{"cell_type":"code","execution_count":29,"source":["soup = BeautifulSoup(html)\r\n","\r\n","print(soup.prettify())"],"outputs":[{"output_type":"stream","name":"stdout","text":["<html>\n"," <body>\n","  <h1>\n","   <a>\n","   </a>\n","   <b>\n","   </b>\n","   <th>\n","   </th>\n","  </h1>\n"," </body>\n","</html>\n"]}],"metadata":{"id":"BeksWqYkmSIt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175050101,"user_tz":-330,"elapsed":1377,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"b426b21f-aff1-4f77-b8c0-536390031022"}},{"cell_type":"markdown","source":["### lxml\n","https://lxml.de/index.html\n","\n","\n","\n","When you create the soup object, you can explicitly specify what parser you want to use. Here we want to explicitly use the lxml parser, and here is the parsed HTML. "],"metadata":{"id":"m1GCjfDPmSIu"}},{"cell_type":"code","execution_count":null,"source":["soup = BeautifulSoup(html, 'lxml')\r\n","\r\n","print(soup.prettify())"],"outputs":[{"output_type":"stream","name":"stdout","text":["<html>\n"," <body>\n","  <h1>\n","   <a>\n","   </a>\n","   <b>\n","   </b>\n","   <th>\n","   </th>\n","  </h1>\n"," </body>\n","</html>\n"]}],"metadata":{"id":"K1W9l7FHmSIv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175052550,"user_tz":-330,"elapsed":1237,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"cbb9cc85-9e47-4011-e931-bde22b9b5fc7"}},{"cell_type":"markdown","source":["### html.parser"],"metadata":{"id":"IMejBxs6OdAb"}},{"cell_type":"markdown","source":["You can construct your soup object using Python's default HTML parser as well. \n","\n","**This has good speed, it's a fairly lenient parser, but it's not as fast as lxml, and this parser is not as lenient as the html5lib parser.**\n","\n","Let's take a look at the resulting HTML when we use this html.parser. \n"],"metadata":{"id":"Iu0T-AlJLc5O"}},{"cell_type":"code","execution_count":27,"source":["soup = BeautifulSoup(html, 'html.parser')\r\n","\r\n","print(soup.prettify())"],"outputs":[{"output_type":"stream","name":"stdout","text":["<h1>\n"," <a>\n"," </a>\n"," <b>\n","  <th <td=\"\">\n","  </th>\n"," </b>\n","</h1>\n"]}],"metadata":{"id":"hcuS-ROsmSIw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175055115,"user_tz":-330,"elapsed":866,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"bcb36bc3-4288-413d-fd53-53cd96f31fd1"}},{"cell_type":"markdown","source":["The resulting HTML is **not as clean** as the HTML that was generated when we use the lxml parser. "],"metadata":{"id":"Ug5SINnVLuj_"}},{"cell_type":"markdown","source":["### html5lib"],"metadata":{"id":"5zJoEh6XOk6f"}},{"cell_type":"markdown","source":["If you want your soup objects to have a **valid HTML5 format**, the html5lib parser is the one that you should use. \n","\n","It's extremely lenient, it parses pages as a web browser does. The resulting HTML will be valid HTML5. \n","\n","However, this is fairly slow and has an external dependency on a Python library. And here is valid HTML5 generated using our html5lib parser. "],"metadata":{"id":"9DMUrPhVLyYN"}},{"cell_type":"code","execution_count":30,"source":["soup = BeautifulSoup(html, 'html5lib')\r\n","\r\n","print(soup.prettify())"],"outputs":[{"output_type":"stream","name":"stdout","text":["<html>\n"," <head>\n"," </head>\n"," <body>\n","  <h1>\n","   <a>\n","    <b>\n","    </b>\n","   </a>\n","  </h1>\n"," </body>\n","</html>\n"]}],"metadata":{"id":"8fItesYcmSIx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175058095,"user_tz":-330,"elapsed":1338,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"d392dabd-17b0-4867-9ef0-5ee6ae69bfc6"}},{"cell_type":"markdown","source":["Beautiful Soup can be used to parse **XML trees** as well. Simply specify XML as your parse format and observe that your resulting HTML page is now rendered as XML. "],"metadata":{"id":"l5aUyx7SL3g9"}},{"cell_type":"code","execution_count":31,"source":["soup = BeautifulSoup(html, 'xml')\r\n","\r\n","print(soup.prettify())"],"outputs":[{"output_type":"stream","name":"stdout","text":["<?xml version=\"1.0\" encoding=\"utf-8\"?>\n","<h1>\n"," <a/>\n"," <b>\n","  <th>\n","   <td/>\n","  </th>\n"," </b>\n","</h1>\n"]}],"metadata":{"id":"YndJNAybmSIy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175060649,"user_tz":-330,"elapsed":879,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"fba28cef-593f-4540-d32a-ab793d0a15f5"}},{"cell_type":"markdown","source":["If you want to use the XML parser in the lxml library, this is how you'd specify your soup object."],"metadata":{"id":"mfOIUrFyL65O"}},{"cell_type":"code","execution_count":32,"source":["soup = BeautifulSoup(html, 'lxml-xml')\r\n","\r\n","print(soup.prettify())"],"outputs":[{"output_type":"stream","name":"stdout","text":["<?xml version=\"1.0\" encoding=\"utf-8\"?>\n","<h1>\n"," <a/>\n"," <b>\n","  <th>\n","   <td/>\n","  </th>\n"," </b>\n","</h1>\n"]}],"metadata":{"id":"ei-cIyy8mSIz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621175064296,"user_tz":-330,"elapsed":1629,"user":{"displayName":"naveen b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfDuIilaUa2Wk0R0x2CQ5B-rp_xEt0Ll-QBw6X=s64","userId":"07342808041236324682"}},"outputId":"8845655c-2ace-4034-f149-59744e87edc5"}}]}